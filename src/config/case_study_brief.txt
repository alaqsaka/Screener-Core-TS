
Mini Project - Backend
Recruitmen
Hello! Thank you for applying with us as a backend developer. This mini project should be completed within 5 days after
you have received this document. Please spare your time to complete this project with the best results. We are really
pleased to answer your questions if there are unclear things.
Objective
Build a backend service that:
1. Accepts a candidate's CV and project report.
2. Compares them with a job vacancy description and the study case brief.
3. Returns a structured evaluation report:
。
。
Match rate between CV and job requirements.
Scoring of project deliverables against standardized parameters.
We want to see your ability to combine backend engineering with Al workflows (prompt design, LLM chaining, retrieval,
resilience).
Deliverables
1. Backend Service (API endpoints)
Implement at least:
•
POST /upload→ Upload CV + Project Report (plain text, PDF, or docx).
•
POST /evaluate → Run evaluation pipeline, returning a JSON response with:
{
}
"id": "456",
"status": "queued"
•
GET /result/{id} → Retrieve evaluation result (simulate async long-running process) with multiple stage:
queued or processing
Ο
{
"id": "456",
"status": "processing"
}
{
completed
"id": "456",
"status": "completed",
"result": {
"cv_match_rate": 0.82,
"cv_feedback": "Strong in backend and cloud, limited AI integration experience.",
"project_score": 7.5,
"project_feedback": "Meets prompt chaining requirements, lacks error handling robustness.",
"overall_summary": "Good candidate fit, would benefit from deeper RAG knowledge."
}
}
2. Evaluation Pipeline
Design an Al-driven pipeline that includes:
a. Prompt Design & LLM Chaining
•
Step 1: Extract structured info from CV (skills, experiences, projects).
•
Step 2: Compare extracted data with job vacancy (LLM prompt).
•
Step 3: Score match rate & generate CV feedback.
•
Step 4: Evaluate project report based on scoring rubric → then refine via second LLM call.
b. RAG (Context Retrieval)
•
Store job description & scoring rubric in a vector database.
•
Retrieve relevant sections and inject into prompts (e.g., "for CV scoring" vs "for project scoring").
c. Long-Running Process Handling
•
POST /evaluate should not block until Al finishes.
•
Store task, return job ID, allow GET /result/{id} to check later.
d. Error Handling & Randomness Control
•
Simulate failures from LLM API (timeouts, rate limit).
•
Implement retries/back-off.
•
Control LLM temperature or add validation layer to keep responses stable.
3. Standardized Evaluation Parameters
Define at least these scoring parameters:
CV Evaluation (Match Rate)
•
Technical Skills Match (backend, databases, APIs, cloud, Al/LLM exposure).
•
Experience Level (years, project complexity).
•
Relevant Achievements (impact, scale).
•
Cultural Fit (communication, learning attitude).
Project Deliverable Evaluation
•
Correctness (meets requirements: prompt design, chaining, RAG, handling errors).
•
Code Quality (clean, modular, testable).
•
Resilience (handles failures, retries).
•
Documentation (clear README, explanation of trade-offs).
•
Creativity / Bonus (optional improvements like authentication, deployment, dashboards).
Each parameter can be scored 1-5, then aggregated to final score.
•
Requirements
Use any backend framework (Rails, Django, Node.js, etc.).
•
Use an LLM (OpenAI or Gemini or OpenRouter). If unavailable, mock the responses.
•
Use a simple vector DB.
•
Provide README with run instructions + explanation of design choices.
Study Case Submission Template
Please use this template to document your solution. Submit it as a PDF file along with your project repository.
1. Title
2. Candidate Information
•
Full Name:
•
Email Address:
3. Repository Link
•
Provide a link to your GitHub repository.
•
•
▲ Important: Do not use the word  anywhere in your repository name, commits, or documentation. This is to
reduce plagiarism risk.
Example: github.com/username/ai-cv-evaluator
4. Approach & Design (Main Section)
Tell the story of how you approached this challenge. We want to understand your thinking process, not just the code.
Please include:
•
Initial Plan
•
•
。
How you broke down the requirements.
Key assumptions or scope boundaries.
System & Database Design
。
。
API endpoints design.
Database schema (diagram or explanation).
Job queue / long-running task handling.
LLM Integration
。
Why you chose a specific LLM or provider.
。
。
。
Prompt design decisions.
Chaining logic (if any).
RAG (retrieval, embeddings, vector DB) strategy.
•
Resilience & Error Handling
。
。
How you handled API failures, timeouts, or randomness.
Any retry, backoff, or fallback logic.
•
Edge Cases Considered
。
What unusual inputs or scenarios you thought about.
How you tested them.
This is your chance to be a storyteller. Imagine you're presenting to a CTO, clarity and reasoning matter more than
buzzwords.
5. Results & Reflection
•
Outcome
。
What worked well in your implementation?
•
•
。
What didn't work as expected?
Evaluation of Results
。
If the evaluation scores/outputs were bad or inconsistent, explain why.
If they were good, explain what made them stable.
Future Improvements
。
What would you do differently with more time?
What constraints (time, tools, API limits) affected your solution?
6. (Optional) Bonus Work
If you added extra features, describe them here.
Product Engineer (Backend) 2025
 is hiring a Product Engineer (Backend) to work on . We're looking for dedicated engineers who write code
they're proud of and who are eager to keep scaling and improving complex systems, including those powered by Al.
About the Job
You'll be building new product features alongside a frontend engineer and product manager using our Agile methodology,
as well as addressing issues to ensure our apps are robust and our codebase is clean. As a Product Engineer, you'll write
clean, efficient code to enhance our product's codebase in meaningful ways.
In addition to classic backend work, this role also touches on building Al-powered systems, where you'll design and
orchestrate how large language models (LLMs) integrate into 's product ecosystem.
Here are some real examples of the work in our team:
•
•
•
•
Collaborating with frontend engineers and 3rd parties to build robust backend solutions that support highly
configurable platforms and cross-platform integration.
Developing and maintaining server-side logic for central database, ensuring high performance throughput and response
time.
Designing and fine-tuning Al prompts that align with product requirements and user contexts.
Building LLM chaining flows, where the output from one model is reliably passed to and enriched by another.
•
Implementing Retrieval-Augmented Generation (RAG) by embedding and retrieving context from vector databases,
then injecting it into Al prompts to improve accuracy and relevance.
•
•
•
•
•
•
•
•
Handling long-running Al processes gracefully - including job orchestration, async background workers, and retry
mechanisms.
Designing safeguards for uncontrolled scenarios: managing failure cases from 3rd party APIs and mitigating the
randomness/nondeterminism of LLM outputs.
Leveraging Al tools and workflows to increase team productivity (e.g., Al-assisted code generation, automated QA,
internal bots).
Writing reusable, testable, and efficient code to improve the functionality of our existing systems.
Strengthening our test coverage with RSpec to build robust and reliable web apps.
Conducting full product lifecycles, from idea generation to design, implementation, testing, deployment, and
maintenance.
Providing input on technical feasibility, timelines, and potential product trade-offs, working with business divisions.
Actively engaging with users and stakeholders to understand their needs and translate them into backend and Al-
driven improvements.
About You
We're looking for candidates with a strong track record of working on backend technologies of web apps, ideally with
exposure to AI/LLM development or a strong desire to learn.
You should have experience with backend languages and frameworks (Node.js, Django, Rails), as well as modern backend
tooling and technologies such as:
•
•
Database management (MySQL, PostgreSQL, MongoDB)
RESTful APIs
•
Security compliance
•
Cloud technologies (AWS, Google Cloud, Azure)
•
Server-side languages (Java, Python, Ruby, or JavaScript)
•
•
Understanding of frontend technologies
User authentication and authorization between multiple systems, servers, and environments
•
Scalable application design principles
•
Creating database schemas that represent and support business processes
•
Implementing automated testing platforms and unit tests
•
Familiarity with LLM APIs, embeddings, vector databases and prompt design best practices
We're not big on credentials, so a Computer Science degree or graduating from a prestigious university isn't something we
emphasize. We care about what you can do and how you do it, not how you got here.
While you'll report to a CTO directly,  is a company where Managers of One thrive. We're quick to trust that you
can do it, and here to support you. You can expect to be counted on and do your best work and build a career here.
This is a remote job. You're free to work where you work best: home office, co-working space, coffee shops. To ensure time
zone overlap with our current team and maintain well communication, we're only looking for people based in Indonesia.
Benefits & Perks
Our benefits support a life well-lived away from work. Ample time off and all the resources you need to support you in
doing the best work of your career:
1. Paid time off:  offers 17 days of vacation and personal days. You can take a day off without any specific
reason, whether you want to hang out, take a vacation, or just lay in bed.
2. Learning benefits with total Rp29 million per year:
。
。
。
Rp6 million per year to subscribe to courses, buy books, or any resources you need to boost your skills and
knowledge.
O'Reilly subscription worth Rp8 million per year We subscribe to O'Reilly for you so you can read the newest
books, videos, conferences, and courses related to technology, data, design, business, and soft skills.
Access to all our learning module Bootcamps and Short Courses worth Rp15 million per year, so you can always
upskill and reskill for a better life and career.
3. Device ownership: We provide a Rp7 million budget per year so you can purchase any device to support your
productivity.
Scoring Rubric for Study Case Evaluation
CV Match Evaluation (1–5 scale per parameter)
Parameter
Description
Technical Skills Match (Weight: Alignment with job requirements (backend,
40%)
databases, APIs, cloud, Al/LLM).
Experience Level (Weight:
25%)
Years of experience and project complexity.
Relevant Achievements
(Weight: 20%)
Cultural / Collaboration Fit
(Weight: 15%)
Impact of past work (scaling, performance,
adoption).
Communication, learning mindset,
teamwork/leadership.
Scoring Guide
1 = Irrelevant skills, 2 = Few overlaps, 3 =
Partial match, 4 = Strong match, 5 =
Excellent match + AI/LLM exposure
1 = <1 yr / trivial projects, 2 = 1-2 yrs, 3 =
2-3 yrs with mid-scale projects, 4 = 3-4
yrs solid track record, 5 = 5+ yrs / high-
impact projects
1 = No clear achievements, 2 = Minimal
improvements, 3 = Some measurable
outcomes, 4 = Significant contributions,
5 = Major measurable impact
1 = Not demonstrated, 2 = Minimal, 3 =
Average, 4 = Good, 5 = Excellent and
well-demonstrated
Project Deliverable Evaluation (1–5 scale per parameter)
Parameter
Correctness (Prompt &
Chaining) (Weight: 30%)
Code Quality & Structure
(Weight: 25%)
Resilience & Error Handling
(Weight: 20%)
Documentation & Explanation
(Weight: 15%)
Description
Implements prompt design, LLM chaining, RAG
context injection.
Clean, modular, reusable, tested.
Handles long jobs, retries, randomness, API
failures.
README clarity, setup instructions, trade-off
explanations.
Creativity / Bonus (Weight: 10%) Extra features beyond requirements.
Scoring Guide
1 = Not implemented, 2 = Minimal
attempt, 3 = Works partially, 4 = Works
correctly, 5 = Fully correct + thoughtful
1 = Poor, 2 = Some structure, 3 = Decent
modularity, 4 = Good structure + some
tests, 5 = Excellent quality + strong tests
1 = Missing, 2 = Minimal, 3 = Partial
handling, 4 = Solid handling, 5 = Robust,
production-ready
1 = Missing, 2 = Minimal, 3 = Adequate, 4
= Clear, 5 = Excellent + insightful
1 = None, 2 = Very basic, 3 = Useful
extras, 4 = Strong enhancements, 5 =
Outstanding creativity
3. Overall Candidate Evaluation
•
CV Match Rate: Weighted Average (1-5) → Convert to % (×20)
•
Project Score: Weighted Average (1-5)
•
Overall Summary: Service should return 3-5 sentences (strengths, gaps, recommendations).
